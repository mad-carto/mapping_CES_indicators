{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# S2 - Geosocial Media Data Text Classification\n",
    "<a class=\"tocSkip\"></a>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook is part of the Supplementary Material provided for the paper\n",
    "_Mapping indicators of cultural ecosystem services use in urban green spaces based on text classification of geosocial media data_ published in the Ecosystem Services: Science, Policy & Practice Journal. This includes the HTML conversions of a series of three Jupyter notebooks as follows: \n",
    "\n",
    "    1. S1_GSM_Data_Processing&LanguageModelTraining.html\n",
    "    2. S2_GSM_Data_TextClassification.html\n",
    "    3. S3_Generate_ChiValueExpectationSurface.html\n",
    "https://doi.org/10.1016/j.ecoser.2022.101508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook the following processes are addressed:\n",
    "\n",
    "    1. Creation of IDF dictionary for the calculation of the TF-IDF score used for the computation of the post embeddings\n",
    "    2. Definition of labels and computation of label embeddings\n",
    "    3. Classification of geosocial media posts related to aesthetic appreciation\n",
    "    4. Classification of geosocial media posts related to wildlife recreation\n",
    " \n",
    "**Input data**:\n",
    " - normalized Instagram and Flickr textual annotations in English and German (.csv file)\n",
    " - corpus containing all normalized Instagram and Flickr textual annotations (.txt file)\n",
    " - word2vec language model trained on geosocial media corpus (.model file)\n",
    "\n",
    "**Output data**:\n",
    " - classified Instagram and Flickr textual annotations in English and German (.csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Last update: 2023-01-02**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from IPython.display import clear_output, display, Markdown\n",
    "date = dt.date.today()\n",
    "display(Markdown(f'**Last update: {date}**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1. Load Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - gensim - version 4.1.2\n",
    " - numpy - version 1.21.3\n",
    " - pandas - version 1.3.3\n",
    " - scipy - version 1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = Path.cwd() / '01_Input'\n",
    "OUTPUT = Path.cwd() / '02_Output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Parse the normalized geosocial media posts into a pandas dataframe\n",
    "\n",
    "see notebook  [S1_GSM_Data_Processing&LanguageModelTraining.ipynb](./S1_GSM_Data_Processing&LanguageModelTraining.ipynb)  for details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_normalized_file = OUTPUT/'Normalized_GeosocialMediaData.csv'\n",
    "cols = ['origin_id', 'latitude', 'longitude', 'user_guid', 'post_date','tags','post_title','post_body','post_text']\n",
    "dtypes={'origin_id': str,'latitude': float, 'longitude': float, 'user_guid': str, 'post_date': str,'tags':str,'post_title':str,'post_body':str, 'post_text':str}\n",
    "df = pd.read_csv(gsm_normalized_file,usecols=cols, dtype=dtypes, encoding = 'utf-8')\n",
    "print(len(df),'normalized posts for DD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3. Load the pre-trained Word2Vec model\n",
    "\n",
    "load the pretrained word2vec model usign gensim's Word2Vec\n",
    "see notebook  [S1_GSM_Data_Processing&LanguageModelTraining.ipynb](./S1_GSM_Data_Processing&LanguageModelTraining.ipynb)  for details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model_file = str( OUTPUT /'word2vec_GeosocialMedia.model')\n",
    "model_w2v = Word2Vec.load(lang_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Topic Classification of Social Media Posts\n",
    "\n",
    "### Workflow\n",
    "\n",
    "The classification of the geosocial media posts is based on the calculation of the similarity score (**cosine similarity**) between a **label embedding** &  the **post embeddings** and follows the workflow exposed below:\n",
    "\n",
    "1. Labels are conceptualized as a collection of words that semantically define the topics we are interested in. For each label a list of relevant keywords in English and German is defined and enhanced by seeking further semantically similar words through the identification of the top 10 most similar words in our geosocial media corpus. \n",
    "\n",
    "2. Each *label embedding* is computed by averaging the embeddings of its constituent words.\n",
    "\n",
    "3. _Post embeddings_ are computed for each geosocial media post by calculating the weighted average of  the constituent words embeddings (we use TF-IDF scores as weighting factors)\n",
    "\n",
    "4. we calculate the cosine similarity (in here _cosine distance_, which is defined as _1- cosine similarity_) between each post embedding and each of the label embeddings to determine if the geosocial media post is related to one of the topics considered. The thresholds for the cosine similarity measure were empirically determined employing a method proposed by Orkphol and Yang (2019), which includes the following steps:\n",
    "    - Step 1: we randomly selected a sample dataset of 1,000 geosocial media posts for each of the topic, which was then manually annotated based on the relevance of each geosocial media post for each of the two studied topics (binarily encoded with 1 as being related to the topic and 0 as being unrelated to the topic).\n",
    "    - Step 2: we calculated the cosine similarity scores between each of the annotated social media post and each of the two label embeddings.\n",
    "    - Step 3: For each topic, a binary logistic regression model was built on 30% of the sample dataset, with the relevance defining the response variable and the cosine similarity values as the predictor.\n",
    "    - Step 4: The threshold for each topic was then estimated by applying the models to obtain predicted probabilities for each geosocial media post in the remaining test datasets. The threshold corresponds to cutoff value for the cosine similarity measure where the predicted probability becomes greater than 0.5.\n",
    "\n",
    "    Based on the results, we set 0.65 as the discrimination threshold of the cosine similarity (0.35 for the cosine distance) for both topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Create IDF-Scores Dictionary (needed for the calculation of TF-IDF score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus created to train the word2vec model\n",
    "corpus_file = OUTPUT/'corpus_GeosocialMedia.txt'\n",
    "\n",
    "# read corpus file into a list\n",
    "corpus = [line.rstrip('\\n') for line in open(corpus_file)]\n",
    "\n",
    "# create Document Frequency dictionary for all the tokens in the corpus\n",
    "doc_frequency = {}\n",
    "for i in range(0,len(corpus)):\n",
    "    tokens = corpus[i]\n",
    "    for w in tokens.split(' '):\n",
    "        try:\n",
    "            doc_frequency[w].add(i)\n",
    "        except:\n",
    "            doc_frequency[w] = {i}\n",
    "            \n",
    "for i in doc_frequency:\n",
    "    doc_frequency[i]= len(doc_frequency[i])\n",
    "    \n",
    "vocabulary = [w for w in doc_frequency]\n",
    "vocabulary_lenght = len(vocabulary)\n",
    "\n",
    "# create dictionary of idf-scores for all the tokens in the vocabulary\n",
    "idf_scores = {}\n",
    "for w in vocabulary:\n",
    "    dfreq = doc_frequency[w]\n",
    "    idf = np.log(vocabulary_lenght/dfreq)\n",
    "    idf_scores[w] = idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2. Calculate _label embeddings_ and _post embeddings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_vector_representation(lang_model, text):\n",
    "    \"\"\"Word2Vec cannot handle out-of-vocabulary; to avoid errors we check\n",
    "    if at least one word of the document is in the word2vec dictionary\"\"\"\n",
    "    n= len([w for w in text if w in list(lang_model.wv.key_to_index.keys())])\n",
    "    if n>0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def avg_topic_vector(lang_model, tokens_list):\n",
    "    # remove out-of-vocabulary words\n",
    "    tokens = []\n",
    "    for token in tokens_list:\n",
    "        if token in list(lang_model.wv.key_to_index.keys()):\n",
    "            tokens.append(token)\n",
    "    return np.average(lang_model.wv[tokens], axis=0)\n",
    "\n",
    "def avg_post_vector(lang_model, tokens_list,idf):\n",
    "    tokens = []\n",
    "    weights = []\n",
    "    for token in tokens_list:\n",
    "        if token in list(lang_model.wv.key_to_index.keys()):\n",
    "            tokens.append(token)\n",
    "            tf = tokens_list.count(token)/len(tokens_list)\n",
    "            tfidf= tf*idf[token]\n",
    "            weights.append(tfidf)\n",
    "    return np.average(lang_model.wv[tokens], weights =weights, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"color: black;\"> \n",
    "   <details><summary> <b> Definition and computation of label embeddings</b></summary> </br>\n",
    "Topics:\n",
    "    <br> \n",
    "    <b> 1. Selfies </b>\n",
    "    <br>\n",
    "Social media platforms such as Instagram are often  used for marketing and self-promotions purposes. Thus, a large volume of the content shared on this platform is represented by portrait photography (\"selfies\") and fashion-related posts. Furthermore, photography designated platforms such as Flickr also contain a significant number of portraits or fashion photography media objects.  This content is not relevant for our analysis (when it comes to aesthetic appreciation and wildlife recreation) therefore, it needs to  be filtered out from our dataset.\n",
    "    <br>\n",
    "    <b> 2. Aesthetic appreciation </b> \n",
    "    <br>\n",
    "To identify Flickr and Instagram posts related to aesthetic appreciation we compiled a list of English and German keywords that describe aesthetic, nature, and landscape photography.\n",
    "    <br>\n",
    "    <b> 3. Wildlife recreation </b>\n",
    "For the identification of the geosocial media posts related to wildlife observations and photography we compiled a list of words describing fauna and flora and disregarded any words related to animals kept in zoos, pets, or animal tattoos for the definition of the topic (as a disambiguation step). \n",
    "    <br>\n",
    "\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions will create an extensive lists of terms for each label\n",
    "def expand_topic_list (topic_li):\n",
    "    enhanced_list = []\n",
    "    for keyword in topic_li:\n",
    "        similar_words = model_w2v.wv.most_similar(positive = [keyword])\n",
    "        enhanced_list += [w[0] for w in similar_words]\n",
    "    enhanced_list += topic_li\n",
    "    return set(enhanced_list)\n",
    "\n",
    "#used for the disambiguation step\n",
    "def difference(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value not in lst2] \n",
    "    return lst3\n",
    "\n",
    "#selfie embedding\n",
    "\n",
    "selfie_list = ['selfie','portrait','porträt','girl','boy','mädchen','cosmetic',\n",
    "               'kosmetik','makeup','beauty','model','fashion']\n",
    "selfie = expand_topic_list(selfie_list)\n",
    "selfie_embedding = avg_topic_vector(model_w2v,selfie)\n",
    "\n",
    "#aesthetic embedding\n",
    "\n",
    "aesthetic_list = ['aesthetic','beautiful','breathtaking','brilliant','enchanting','enjoying','gorgeous',\n",
    "                  'landscape', 'magnificent', 'nature', 'outdoor', 'outstanding','panorama','pretty',\n",
    "                  'scenery','scenic','splendid', 'ausblick', 'ansicht', 'aussicht','bezaubernd','genießen',\n",
    "                  'großartig', 'kulturlandschaft', 'landschaft', 'landschaftlich','natur','prachtvoll','prächtig',\n",
    "                  'rundblick','toll','überwältigend']\n",
    "aesthetic = expand_topic_list(aesthetic_list)\n",
    "aesthetic_embedding = avg_topic_vector(model_w2v,aesthetic)\n",
    "\n",
    "#wildlife embedding\n",
    "\n",
    "wildlife_list = ['animal','bird','butterfly','fauna','flora','flower', 'fungus', 'insect', 'mushroom', 'plant', \n",
    "                 'reptile','tree','wild','wildlife','baum','blume','insekt','kerbtier','pflanze','pilz',\n",
    "                 'schmetterling','tiere','tierwelt','vogel']\n",
    "wildlife_disambiguation = ['pet','haustier','zoo','tiergarten','tierpark','zoologischergarten','tattoo','dog',\n",
    "                              'hund','cat','katze']\n",
    "wildlife = difference(expand_topic_list(wildlife_list),expand_topic_list(wildlife_disambiguation))\n",
    "wildlife_embedding = avg_topic_vector(model_w2v,wildlife)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Classify the geosocial media posts and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns to the dataframe to save the classification results\n",
    "df.reindex(df.columns.tolist() + ['selfie','cos_dist_selfie',\n",
    "                                            'aesthetic','cos_dist_aesthetic',\n",
    "                                            'wildlife', 'cos_dist_wildlife'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x = 0\n",
    "total_records = len(df)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    x+=1\n",
    "    msg_text = (\n",
    "        f'Processed records: {x} ({x/(total_records/100):.2f}%). ')\n",
    "    if x % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(msg_text)\n",
    "        \n",
    "    text = row['post_text'].split(' ')\n",
    "    if has_vector_representation(model_w2v, text) == True:\n",
    "        post_embedding = avg_post_vector(model_w2v, text, idf_scores)\n",
    "        cos_dist_selfie = scipy.spatial.distance.cosine(selfie_embedding, post_embedding, w=None)\n",
    "        cos_dist_aesthetic = scipy.spatial.distance.cosine(aesthetic_embedding, post_embedding, w=None)\n",
    "        cos_dist_wildlife = scipy.spatial.distance.cosine(wildlife_embedding, post_embedding, w=None)\n",
    "        if cos_dist_selfie<0.3:\n",
    "            df.at[index,'selfie'] = 1\n",
    "            df.at[index,'cos_dist_selfie'] = cos_dist_selfie\n",
    "            if cos_dist_aesthetic<0.35:\n",
    "                df.at[index,'aesthetic'] = 2\n",
    "                df.at[index,'cos_dist_aesthetic'] = cos_dist_aesthetic\n",
    "            else:\n",
    "                df.at[index,'aesthetic'] = 0\n",
    "                df.at[index,'cos_dist_aesthetic'] = cos_dist_aesthetic\n",
    "            if cos_dist_wildlife<0.35:\n",
    "                df.at[index,'wildlife'] = 1\n",
    "                df.at[index,'cos_dist_wildlife'] = cos_dist_wildlife\n",
    "            else:\n",
    "                df.at[index,'wildlife'] = 0\n",
    "                df.at[index,'cos_dist_wildlife'] = cos_dist_wildlife\n",
    "\n",
    "        else:\n",
    "            df.at[index,'selfie'] = 0\n",
    "            df.at[index,'cos_dist_selfie'] = cos_dist_selfie\n",
    "            if cos_dist_aesthetic<0.35:\n",
    "                df.at[index,'aesthetic'] = 1\n",
    "                df.at[index,'cos_dist_aesthetic'] = cos_dist_aesthetic\n",
    "            else:\n",
    "                df.at[index,'aesthetic'] = 0\n",
    "                df.at[index,'cos_dist_aesthetic'] = cos_dist_aesthetic\n",
    "            if cos_dist_wildlife<0.35:\n",
    "                df.at[index,'wildlife'] = 1\n",
    "                df.at[index,'cos_dist_wildlife'] = cos_dist_wildlife\n",
    "            else:\n",
    "                df.at[index,'wildlife'] = 0\n",
    "                df.at[index,'cos_dist_wildlife'] = cos_dist_wildlife\n",
    "# final status\n",
    "clear_output(wait=True)\n",
    "print(msg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as csv file\n",
    "df.to_csv('./02_Output/DD_Flickr&Instagram_Classified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "1. Orkphol, K., & Yang, W. (2019). Word Sense Disambiguation Using Cosine Similarity Collaborates with Word2vec and WordNet. Future Internet, 11(5), 114. https://doi.org/10.3390/fi11050114\n",
    "\n",
    "2. The code used to train determine the cosine similarity thresholds is an adaptation of the notebook proposed by the authors of the method, which is to be found at: \n",
    "https://anaconda.org/korawit/similarity_threshold/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
